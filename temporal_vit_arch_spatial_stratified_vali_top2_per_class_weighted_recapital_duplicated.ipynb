{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python dependencies\n",
    "\n",
    "# %pip install torch torchvision timm pandas geopandas numpy opencv-python scikit-learn matplotlib folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python packages\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import folium\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory and cache\n",
    "\n",
    "# del model, optimizer, images, labels, outputs\n",
    "# del model, optimizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device for torch backend\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure images, deomgraphic data and labels.\n",
    "\n",
    "class UrbanRetrofittingDataset(Dataset):\n",
    "    def __init__(self, excel_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            excel_file (str): Path to the Excel file with annotations.\n",
    "            image_dir (str): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image pair.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_excel(excel_file, dtype={\"Latitude\": str, \"Longitude\": str})\n",
    "        # maintains precision. Do not change this two step converesion.\n",
    "        self.data = self.data.astype({\"Latitude\": np.longdouble, \"Longitude\": np.longdouble})\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['Change'] = self.label_encoder.fit_transform(self.data['Change'])  # Encode labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        census_block = str(row['ID'])\n",
    "        lat, lon, direction = row['Latitude'], row['Longitude'], row['Heading']\n",
    "        start_date, end_date = row['Start'], row['End']\n",
    "        pop_density_change = row['PopDen_Diff']\n",
    "        change_percentage = row['PopDen_Diff_Percentage']\n",
    "        label = row['Change']\n",
    "\n",
    "        # Load image pair Do not use f{} formatting to add longdouble number\n",
    "        start_image_path = os.path.join(self.image_dir, census_block,  str(lat)+\"_\"+str(lon)+\"_\"+str(direction), f\"{pd.to_datetime(start_date).strftime('%b %Y')}.png\")\n",
    "        end_image_path = os.path.join(self.image_dir, census_block, str(lat)+\"_\"+str(lon)+\"_\"+str(direction), f\"{pd.to_datetime(end_date).strftime('%b %Y')}.png\")\n",
    "        start_image = Image.open(start_image_path).convert('RGB')\n",
    "        end_image = Image.open(end_image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            start_image = self.transform(start_image)\n",
    "            end_image = self.transform(end_image)\n",
    "\n",
    "        # socio-economic data\n",
    "        socio_economic_data = torch.tensor([pop_density_change, change_percentage], dtype=torch.float32)\n",
    "\n",
    "        return start_image, end_image, socio_economic_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "\n",
    "class ViTWithSocioEconomic(nn.Module):\n",
    "    def __init__(self, num_numeric_features, num_classes):\n",
    "        super(ViTWithSocioEconomic, self).__init__()\n",
    "        # Pretrained ViT model from timm library without classification head to get image embeddings.\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n",
    "        img_embedding_dim = self.vit.num_features\n",
    "\n",
    "        # Numeric features embedding\n",
    "        self.numeric_embed = nn.Sequential(\n",
    "            nn.Linear(num_numeric_features, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3 * img_embedding_dim + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, start_image, end_image, numeric_feats):\n",
    "        start_feat = self.vit(start_image)\n",
    "        end_feat = self.vit(end_image)\n",
    "        diff_feat = end_feat - start_feat\n",
    "        numeric_feat = self.numeric_embed(numeric_feats)\n",
    "        combined = torch.cat([start_feat, end_feat, diff_feat, numeric_feat], dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with per-class accuracy and loss tracking\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, num_classes):\n",
    "    model.train()\n",
    "    total_samples = 0\n",
    "    running_loss = 0.0\n",
    "    correct_total = 0\n",
    "    \n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    class_losses = [0.0] * num_classes\n",
    "    \n",
    "    for start_imgs, end_imgs, socio_econ, labels in loader:\n",
    "        start_imgs, end_imgs = start_imgs.to(device), end_imgs.to(device)\n",
    "        socio_econ, labels = socio_econ.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(start_imgs, end_imgs, socio_econ)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct_total += (preds == labels).sum().item()\n",
    "\n",
    "        for cls in range(num_classes):\n",
    "            cls_mask = labels == cls\n",
    "            if cls_mask.sum() > 0:\n",
    "                cls_outputs = outputs[cls_mask]\n",
    "                cls_labels = labels[cls_mask]\n",
    "                class_losses[cls] += criterion(cls_outputs, cls_labels).item() * cls_mask.sum().item()\n",
    "                class_correct[cls] += (cls_outputs.argmax(dim=1) == cls_labels).sum().item()\n",
    "                class_total[cls] += cls_mask.sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    overall_acc = 100 * correct_total / total_samples\n",
    "\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] if class_total[i] else 0 for i in range(num_classes)]\n",
    "    class_avg_loss = [class_losses[i] / class_total[i] if class_total[i] else 0 for i in range(num_classes)]\n",
    "\n",
    "    return epoch_loss, overall_acc, class_acc, class_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function with top-2 accuracy and per-class metrics\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device, num_classes):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    running_loss = 0.0\n",
    "    correct_total = 0\n",
    "\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    class_losses = [0.0] * num_classes\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_imgs, end_imgs, socio_econ, labels in loader:\n",
    "            start_imgs, end_imgs = start_imgs.to(device), end_imgs.to(device)\n",
    "            socio_econ, labels = socio_econ.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(start_imgs, end_imgs, socio_econ)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            _, preds_top2 = outputs.topk(2, dim=1)\n",
    "            correct_top2 = preds_top2.eq(labels.unsqueeze(1)).any(dim=1)\n",
    "            stored_pred_batch = torch.where(correct_top2, labels, preds_top2[:, 0])\n",
    "\n",
    "            all_preds.extend(stored_pred_batch.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            correct_total += correct_top2.sum().item()\n",
    "\n",
    "            for cls in range(num_classes):\n",
    "                cls_mask = labels == cls\n",
    "                if cls_mask.sum() > 0:\n",
    "                    cls_outputs = outputs[cls_mask]\n",
    "                    cls_labels = labels[cls_mask]\n",
    "                    class_losses[cls] += criterion(cls_outputs, cls_labels).item() * cls_mask.sum().item()\n",
    "                    class_correct[cls] += correct_top2[cls_mask].sum().item()\n",
    "                    class_total[cls] += cls_mask.sum().item()\n",
    "\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    overall_acc = 100 * correct_total / total_samples\n",
    "\n",
    "    class_acc = [100 * class_correct[i] / class_total[i] if class_total[i] else 0 for i in range(num_classes)]\n",
    "    class_avg_loss = [class_losses[i] / class_total[i] if class_total[i] else 0 for i in range(num_classes)]\n",
    "\n",
    "    return epoch_loss, overall_acc, class_acc, class_avg_loss, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for saving and loading checkpoints.\n",
    "checkpoint_dir = \"ViT_checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "MODEL_NAME = \"temporal_vit_spatial_stratified_vali_top2_per_weighted_class_loss_v21\"\n",
    "CHECKPOINT_PATH = f\"{checkpoint_dir}/{MODEL_NAME}_epoch_30.pth\" \n",
    "# directory for storing logs\n",
    "logs_dir = \"logs\"\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "LOG_FILE = f\"{logs_dir}/{MODEL_NAME}.txt\"\n",
    "GRAPH_PATH = f\"Model Graphs/{MODEL_NAME}.png\"\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY_RATE = 0.00001\n",
    "NUM_CLASSES = 5  # Five aspects of urban retrofitting\n",
    "\n",
    "# Dataset and DataLoader\n",
    "excel_File = \"every_10_nochange_recapital_doubled_2013_2023_pop_den_labels.xlsx\"\n",
    "image_dir = \"Streetview_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to file and console\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        # Append mode\n",
    "        logging.FileHandler(LOG_FILE, mode='a'),\n",
    "        # Also print to console\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data transformations\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Spatial stratified sampling split function \n",
    "\n",
    "def spatial_stratified_split(dataset, val_ratio=0.2, n_clusters=10):\n",
    "    \"\"\"\n",
    "    Perform spatial stratified sampling split and return PyTorch-compatible UrbanRetrofittingDataset subsets.\n",
    "    NOTE: n_clusters = 4 included at least 1 sample per class in each cluster. \n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw dataframe loaded from Excel.\n",
    "        image_dir (str): Path to the image directory.\n",
    "        transform (callable): Torchvision transform for images.\n",
    "        val_ratio (float): Ratio for validation split.\n",
    "        n_clusters (int): Number of spatial clusters.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset (Subset), val_dataset (Subset), label_encoder\n",
    "    \"\"\"\n",
    "    df = dataset.data.copy()\n",
    "    \n",
    "    # Ensure correct types\n",
    "    df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "    # Spatial clustering\n",
    "    coords = df[['Latitude', 'Longitude']].values\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['Cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "    # Stratified sampling within each spatial cluster\n",
    "    train_indices, val_indices = [], []\n",
    "\n",
    "    for cluster in df['Cluster'].unique():\n",
    "        cluster_df = df[df['Cluster'] == cluster]\n",
    "        for label in cluster_df['Change'].unique():\n",
    "            label_df = cluster_df[cluster_df['Change'] == label]\n",
    "            n_val = max(1, int(len(label_df) * val_ratio))\n",
    "            val_sample = label_df.sample(n=n_val, random_state=42)\n",
    "            train_sample = label_df.drop(val_sample.index)\n",
    "            train_indices.extend(train_sample.index)\n",
    "            val_indices.extend(val_sample.index)\n",
    "\n",
    "    # Reset index to use Subset\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dataset.data = df\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['Longitude'], df['Latitude']), crs='EPSG:4326')\n",
    "\n",
    "    return train_indices, val_indices, gdf\n",
    "\n",
    "logger.info(\"Data Loading Initiated!\")\n",
    "# initializing dataset twice to use multiple transforms for training and validation.\n",
    "train_dataset = UrbanRetrofittingDataset(excel_File, image_dir, train_transform)\n",
    "val_dataset = UrbanRetrofittingDataset(excel_File, image_dir, val_transform)\n",
    "\n",
    "# use any one to get train and val indices.\n",
    "train_indices, val_indices, clusters_gdf = spatial_stratified_split(dataset=train_dataset, val_ratio=0.2, n_clusters=20)\n",
    "_,_,_ = spatial_stratified_split(dataset=val_dataset, val_ratio=0.2, n_clusters=20)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "val_dataset = Subset(val_dataset, val_indices)\n",
    "logger.info(\"Split data into training and validation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log cluster distribution\n",
    "\n",
    "all_labels = train_dataset.dataset.data['Change']\n",
    "\n",
    "def log_distribution(all_labels, dataset, name):\n",
    "    label_counts = Counter([all_labels[i] for i in dataset.indices])\n",
    "    label_encoder = dataset.dataset.label_encoder\n",
    "    logger.info(f\"{name} distribution:\")\n",
    "    for label_idx in sorted(label_counts):\n",
    "        logger.info(f\"\\t{label_encoder.classes_[label_idx]}: {label_counts[label_idx]}\")\n",
    "\n",
    "log_distribution(all_labels, train_dataset, \"Train\")\n",
    "log_distribution(all_labels, val_dataset, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of clusters and class distribution for training set\n",
    "\n",
    "train_df = train_dataset.dataset.data.loc[train_indices]\n",
    "counts = train_df.groupby(['Cluster', 'Change']).size().unstack(fill_value=0)\n",
    "logger.info(\"Training Sample counts per class in each cluster:\")\n",
    "logger.info(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of clusters and class distribution for validation set\n",
    "\n",
    "val_df = val_dataset.dataset.data.loc[val_indices]\n",
    "counts = val_df.groupby(['Cluster', 'Change']).size().unstack(fill_value=0)\n",
    "logger.info(\"Validation Sample counts per class in each cluster:\")\n",
    "logger.info(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Prepare colors for classes\n",
    "classes = train_dataset.dataset.label_encoder.classes_\n",
    "num_classes = len(classes)\n",
    "colormap = cm.get_cmap('tab10', num_classes)\n",
    "class_colors = {classes[i]: mcolors.rgb2hex(colormap(i)) for i in range(num_classes)}\n",
    "\n",
    "# Get cluster polygons (convex hull)\n",
    "cluster_polys = clusters_gdf[['Cluster', 'geometry']].dissolve(by='Cluster', as_index=False, aggfunc='first')\n",
    "cluster_polys['geometry'] = cluster_polys.geometry.convex_hull\n",
    "cluster_polys = gpd.GeoDataFrame(cluster_polys, geometry=\"geometry\", crs='EPSG:4326')\n",
    "cluster_polys.rename(columns={0: 'geometry'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize clusters and samples using folium map\n",
    "\n",
    "def create_folium_cluster_map(data_gdf, class_colors, title):\n",
    "    m = folium.Map(location=[data_gdf['Latitude'].mean(), data_gdf['Longitude'].mean()], zoom_start=11)\n",
    "    \n",
    "    # Plot clusters (polygons)\n",
    "    for _, row in cluster_polys.iterrows():\n",
    "        folium.GeoJson(\n",
    "            row['geometry'],\n",
    "            style_function=lambda feature, clr=row['Cluster']: {\n",
    "                'fillColor': f\"#cccccc\",\n",
    "                'color': 'black',\n",
    "                'weight': 1,\n",
    "                'fillOpacity': 0.8\n",
    "            },\n",
    "            tooltip=f\"Cluster {row['Cluster']}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Add class samples as points\n",
    "    for _, row in data_gdf.iterrows():\n",
    "        cls = row['Change']\n",
    "        color = class_colors[classes[cls]]\n",
    "        popup = f\"Class: {cls}<br>Cluster: {row['Cluster']}\"\n",
    "        folium.CircleMarker(\n",
    "            location=[row['Latitude'], row['Longitude']],\n",
    "            radius=4,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            popup=popup\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Add legend\n",
    "    legend_html = \"<div style='position: fixed; bottom: 20px; left: 20px; z-index: 9999; background-color: white; padding: 10px; border: 1px solid #ccc;'>\"\n",
    "    legend_html += \"<b>Class Colors</b><br>\"\n",
    "    for cls, color in class_colors.items():\n",
    "        legend_html += f\"<i style='background:{color};width:10px;height:10px;display:inline-block;'></i> {cls}<br>\"\n",
    "    legend_html += \"</div>\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    return m\n",
    "\n",
    "# Generate and save maps\n",
    "train_map = create_folium_cluster_map(train_df, class_colors, \"Training Data Map\")\n",
    "val_map = create_folium_cluster_map(val_df, class_colors, \"Validation Data Map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training set map.\n",
    "train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize validation set map. \n",
    "val_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display traing set dataframe.\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation set dataframe.\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from training dataset\n",
    "# train_labels = [sample[3] for sample in train_dataset]  # sample[3] is the label in __getitem__\n",
    "all_labels = train_dataset.dataset.data['Change'] #defined above already\n",
    "train_labels = [all_labels[i] for i in train_dataset.indices]\n",
    "num_classes = len(set(train_labels))\n",
    "\n",
    "# Compute class sample weights\n",
    "# class_counts = np.array([train_labels.count(i) for i in range(num_classes)])\n",
    "# class_weights_sampler = 1. / class_counts\n",
    "\n",
    "# Class sample weights calculated manually to avoid extreme weights for very rare classes.\n",
    "class_weights_sampler = np.array([0.0036, 0.0034, 0.0150, 0.0050, 0.0060]) # v21\n",
    "sample_weights = np.array([class_weights_sampler[label] for label in train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted sampler for drawing training samples.\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                 num_samples=len(sample_weights),\n",
    "                                 replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute class weights for loss function.\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',\n",
    "#     classes=np.unique(labels),\n",
    "#     y=labels\n",
    "# )\n",
    "\n",
    "# Manually calculated class weights to avoid extreme weights for very rare classes.\n",
    "class_weights = np.array([1.66, 7.22, 5.56, 9.22, 9.34]) #v21\n",
    "\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "logger.info(\"Class weights used for loss function:\")\n",
    "for label, weight in zip(train_dataset.dataset.label_encoder.classes_, class_weights):\n",
    "    logger.info(f\"\\tClass {label}: Weight={weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enable faster data loading using multiple workers for data loading.\n",
    "import multiprocessing\n",
    "num_workers = multiprocessing.cpu_count() // 2\n",
    "num_workers\n",
    "# Above result was 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders.\n",
    "\n",
    "logger.info(f\"Batch Size: {BATCH_SIZE}, Workers: {num_workers}, pin_memory: True, LR: {LEARNING_RATE}, Wt. Decay: {WEIGHT_DECAY_RATE}\")# this will be a lazy loader. Just initialization happens here. Real work happens inside for loop of data loader.\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=num_workers, pin_memory=True)\n",
    "logger.info(\"Training Loader is now ready!\")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "logger.info(\"Validation Loader is now ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ViTWithSocioEconomic(2, NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY_RATE)\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    train_acc_per_class = checkpoint['train_acc_per_class']\n",
    "    val_acc_per_class = checkpoint['val_acc_per_class']\n",
    "    train_loss_per_class = checkpoint['train_loss_per_class']\n",
    "    val_loss_per_class = checkpoint['val_loss_per_class']\n",
    "    overall_train_acc = checkpoint['overall_train_acc']\n",
    "    overall_val_acc = checkpoint['overall_val_acc']\n",
    "    overall_train_loss = checkpoint['overall_train_loss']\n",
    "    overall_val_loss = checkpoint['overall_val_loss']\n",
    "    \n",
    "    val_preds = checkpoint['val_preds']\n",
    "    val_labels = checkpoint['val_labels']\n",
    "    \n",
    "    logger.info(f\"Loaded checkpoint from epoch {start_epoch}\")\n",
    "else:\n",
    "    # Initialize lists to store losses and accuracies\n",
    "    start_epoch = 0\n",
    "    train_acc_per_class = []\n",
    "    val_acc_per_class = []\n",
    "    train_loss_per_class = []\n",
    "    val_loss_per_class = []\n",
    "    overall_train_acc = []\n",
    "    overall_val_acc = []\n",
    "    overall_train_loss = []\n",
    "    overall_val_loss = []\n",
    "    val_preds = None\n",
    "    val_labels = None\n",
    "\n",
    "    logger.info(\"No checkpoint found - starting new training\")\n",
    "\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    train_loss, train_overall_acc,  train_class_acc, train_class_loss = train_epoch(model, train_loader, criterion, optimizer, device, NUM_CLASSES)\n",
    "    val_loss, val_overall_acc, val_class_acc, val_class_loss, val_preds, val_labels  = validate_epoch(model, val_loader, criterion, device, NUM_CLASSES)\n",
    "    \n",
    "    train_acc_per_class.append(train_class_acc)\n",
    "    val_acc_per_class.append(val_class_acc)\n",
    "    train_loss_per_class.append(train_class_loss)\n",
    "    val_loss_per_class.append(val_class_loss)\n",
    "    overall_train_acc.append(train_overall_acc)\n",
    "    overall_val_acc.append(val_overall_acc)\n",
    "    overall_train_loss.append(train_loss)\n",
    "    overall_val_loss.append(val_loss)\n",
    "\n",
    "    logger.info(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    logger.info(f\"Train Accuracy: {train_overall_acc:.2f}%\")\n",
    "    logger.info(f\"Train Loss: {train_loss:.4f}\")\n",
    "    for idx, cls in enumerate(train_dataset.dataset.label_encoder.classes_):\n",
    "        logger.info(f\"\\tTrain Class '{cls}': Acc={train_class_acc[idx]:.2f}%, Loss={train_class_loss[idx]:.4f}\")\n",
    "    \n",
    "    logger.info(f\"Validation Accuracy: {val_overall_acc:.2f}%\")\n",
    "    logger.info(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    for idx, cls in enumerate(train_dataset.dataset.label_encoder.classes_):\n",
    "        logger.info(f\"\\tVal Class '{cls}': Acc={val_class_acc[idx]:.2f}%, Loss={val_class_loss[idx]:.4f}\")\n",
    "\n",
    "    # Save checkpoints every 2 epochs\n",
    "    # if (epoch + 1) % 2 == 0:\n",
    "    if (epoch + 1) >= 18:\n",
    "        CHECKPOINT_PATH = os.path.join(checkpoint_dir, f\"temporal_vit_spatial_stratified_vali_top2_per_weighted_class_loss_v21_epoch_{epoch+1}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_acc_per_class': train_acc_per_class,\n",
    "            'val_acc_per_class': val_acc_per_class,\n",
    "            'train_loss_per_class': train_loss_per_class,\n",
    "            'val_loss_per_class': val_loss_per_class,\n",
    "            'overall_train_acc':overall_train_acc,\n",
    "            'overall_val_acc':overall_val_acc,\n",
    "            'overall_train_loss':overall_train_loss,\n",
    "            'overall_val_loss':overall_val_loss,\n",
    "            'val_preds': val_preds,\n",
    "            'val_labels': val_labels\n",
    "    \n",
    "        }, CHECKPOINT_PATH)\n",
    "        logger.info(f\"Saved checkpoint to {CHECKPOINT_PATH}\")\n",
    "\n",
    "    logger.info(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "classes = val_dataset.dataset.label_encoder.classes_\n",
    "print(classification_report(val_labels, val_preds, target_names=classes, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(val_labels, val_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize accuracy graphs.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define class labels\n",
    "classes = ['No Change', 'Re-building', 'Re-capital', 'Re-inhabitation', 'Re-transportation']\n",
    "\n",
    "color_map = {\n",
    "    'No Change': \"#c2bf04\",         # gold\n",
    "    'Re-building': \"#ff00ff\",       # darkorange\n",
    "    'Re-capital': \"#005E05\",        # magneta\n",
    "    'Re-inhabitation': '#00bfff',   # red\n",
    "    'Re-transportation': '#ff0000'  # deepskyblue\n",
    "}\n",
    "\n",
    "# Epochs\n",
    "epochs = list(range(1, len(train_acc_per_class) + 1))\n",
    "\n",
    "# Helper to convert list of lists to class-wise dict\n",
    "def transpose_to_class_dict(data):\n",
    "    return {cls: [epoch_data[i] for epoch_data in data] for i, cls in enumerate(classes)}\n",
    "\n",
    "# Convert input lists to class-wise dicts\n",
    "train_acc_class = transpose_to_class_dict(train_acc_per_class)\n",
    "val_acc_class = transpose_to_class_dict(val_acc_per_class)\n",
    "train_loss_class = transpose_to_class_dict(train_loss_per_class)\n",
    "val_loss_class = transpose_to_class_dict(val_loss_per_class)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "# Training Accuracy per Class\n",
    "for cls in classes:\n",
    "    axs[0].plot(epochs, train_acc_class[cls], label=cls, color=color_map[cls])\n",
    "axs[0].set_title('Training Accuracy per Category')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy (%)')\n",
    "axs[0].set_xticks(epochs)\n",
    "axs[0].set_xlim(1,30)\n",
    "axs[0].set_ylim(20,100)\n",
    "# axs[0].set_yticks(list(range(0,101,10))) \n",
    "axs[0].legend(loc='lower right')\n",
    "axs[0].legend()\n",
    "\n",
    "# Validation Accuracy per Class\n",
    "for cls in classes:\n",
    "    axs[1].plot(epochs, val_acc_class[cls], label=cls, color=color_map[cls])\n",
    "axs[1].set_title('Validation Accuracy per Category')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Accuracy (%)')\n",
    "axs[1].set_xticks(epochs)\n",
    "axs[1].set_xlim(1,30)\n",
    "axs[1].set_ylim(20,100)\n",
    "axs[1].legend()\n",
    "\n",
    "# Overall Accuracy\n",
    "axs[2].plot(epochs, overall_train_acc, label='Training')\n",
    "axs[2].plot(epochs, overall_val_acc, label='Validation')\n",
    "axs[2].set_title('Overall Accuracy')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Accuracy (%)')\n",
    "axs[2].set_xticks(epochs)\n",
    "axs[2].set_xlim(1,30)\n",
    "axs[2].set_ylim(20,100)\n",
    "axs[2].legend()\n",
    "\n",
    "# turn the grid on for every subplot\n",
    "for ax in axs.ravel():\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(GRAPH_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions of the model\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "model = ViTWithSocioEconomic(2, NUM_CLASSES).to(device)\n",
    "CHECKPOINT_PATH = \"ViT_checkpoints/temporal_vit_spatial_stratified_vali_top2_per_weighted_class_loss_v21_epoch_30.pth\"\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Re-run validation to get all outputs\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        start_imgs, end_imgs, socio_econ, labels = batch\n",
    "        start_imgs, end_imgs = start_imgs.to(device), end_imgs.to(device)\n",
    "        socio_econ, labels = socio_econ.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(start_imgs, end_imgs, socio_econ)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        top_probs, preds = torch.max(probs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(top_probs.cpu().numpy())\n",
    "\n",
    "        # Save for visualization\n",
    "        for i in range(len(labels)):\n",
    "            sample = val_dataset[i]  # since it's a Subset\n",
    "            metadata = val_dataset.dataset.data.iloc[val_dataset.indices[i]]\n",
    "            all_paths.append({\n",
    "                'start_img': start_imgs[i].cpu(),\n",
    "                'end_img': end_imgs[i].cpu(),\n",
    "                'label': labels[i].item(),\n",
    "                'pred': preds[i].item(),\n",
    "                'confidence': top_probs[i].item(),\n",
    "                'census_block': metadata['ID'],\n",
    "                'lat': metadata['Latitude'],\n",
    "                'lon': metadata['Longitude'],\n",
    "                'heading': metadata['Heading'],\n",
    "                'start_date': metadata['Start'],\n",
    "                'end_date': metadata['End']\n",
    "            })\n",
    "\n",
    "# Organize samples by class\n",
    "class_samples = {i: {'correct': [], 'incorrect': []} for i in range(NUM_CLASSES)}\n",
    "\n",
    "for info in all_paths:\n",
    "    cls = info['label']\n",
    "    if info['pred'] == info['label']:\n",
    "        if len(class_samples[cls]['correct']) < 1:\n",
    "            class_samples[cls]['correct'].append(info)\n",
    "    else:\n",
    "        if len(class_samples[cls]['incorrect']) < 1:\n",
    "            class_samples[cls]['incorrect'].append(info)\n",
    "\n",
    "# Define label map\n",
    "label_map = dict(enumerate(val_dataset.dataset.label_encoder.classes_))\n",
    "\n",
    "# Plotting function\n",
    "def plot_sample(info):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    for i, (img, label) in enumerate(zip([info['start_img'], info['end_img']], ['Start', 'End'])):\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]  # Unnormalize\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{label}: {info['start_date'] if label=='Start' else info['end_date']}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Predicted: {label_map[info['pred']]} ({info['confidence']*100:.2f}%) | Actual: {label_map[info['label']]}\\nCensus Block: {info['census_block']} | Location: {info['lat']}, {info['lon']} | Heading: {info['heading']}\",\n",
    "        color='green' if info['pred'] == info['label'] else 'red',\n",
    "        fontsize=10\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display 2 per class (correct + incorrect)\n",
    "for cls in range(NUM_CLASSES):\n",
    "    if class_samples[cls]['correct']:\n",
    "        plot_sample(class_samples[cls]['correct'][0])\n",
    "    if class_samples[cls]['incorrect']:\n",
    "        plot_sample(class_samples[cls]['incorrect'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model's prediction for full dataset to an excel file from which accracy for each category across census blocks group can be calculated.\n",
    "\n",
    "# Data Loading\n",
    "# Dataset and DataLoader\n",
    "excel_File = \"every_10_nochange_recapital_doubled_2013_2023_pop_den_labels.xlsx\"\n",
    "image_dir = \"Streetview_data\"\n",
    "BATCH_SIZE = 256\n",
    "NUM_CLASSES = 5\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load entire dataset first with val_transform (no augmentation, just resizing and normalization)\n",
    "full_dataset = UrbanRetrofittingDataset(excel_File, image_dir, val_transform)\n",
    "\n",
    "# Get only validation subset using original val_indices\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "data_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "model = ViTWithSocioEconomic(2, NUM_CLASSES).to(device)\n",
    "CHECKPOINT_PATH = \"ViT_checkpoints/temporal_vit_spatial_stratified_vali_top2_per_weighted_class_loss_v21_epoch_30.pth\"\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions and true labels\n",
    "all_preds = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start_imgs, end_imgs, socio_econ, labels in data_loader:\n",
    "        start_imgs = start_imgs.to(device)\n",
    "        end_imgs = end_imgs.to(device)\n",
    "        socio_econ = socio_econ.to(device)\n",
    "\n",
    "        outputs = model(start_imgs, end_imgs, socio_econ)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Reload original Excel (to retain all original columns)\n",
    "df = pd.read_excel(excel_File, dtype={\"Latitude\": str, \"Longitude\": str})\n",
    "df = df.astype({\"Latitude\": np.longdouble, \"Longitude\": np.longdouble})\n",
    "\n",
    "# Fit label encoder again to get label mappings\n",
    "label_encoder = LabelEncoder()\n",
    "df['Change_Encoded'] = label_encoder.fit_transform(df['Change'])\n",
    "\n",
    "# Add predictions\n",
    "df['Prediction'] = all_preds\n",
    "df['Prediction_Label'] = label_encoder.inverse_transform(df['Prediction'].astype(int))\n",
    "\n",
    "# Save to new Excel\n",
    "output_excel = \"val_dataset_predictions_for_mapping.xlsx\"\n",
    "df.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"âœ… Predictions for entire dataset saved to: {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, calculate accuracy for each category across census blocks group and merge with shapefile for model accuracy visualization.\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Load files\n",
    "excel_file = \"val_dataset_predictions_for_mapping.xlsx\"\n",
    "shp_file = \"Shapefile/mecklengburg_county_census_block_group_2013.shp\"\n",
    "output_shp = \"Shapefile/latest_accuracy_per_census_block_group.shp\"\n",
    "\n",
    "# Load Excel data\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "# Ensure ID is string for merge\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "\n",
    "# List all unique true change categories in the dataset\n",
    "all_categories = df['Change'].dropna().unique()\n",
    "\n",
    "# Function to compute accuracy metrics per Census Block Group\n",
    "def compute_accuracy(group):\n",
    "    total = len(group)\n",
    "    correct = (group['Change'] == group['Prediction_Label']).sum()\n",
    "    overall_acc = round((correct / total) * 100, 2) if total else np.nan\n",
    "    result = {'overall_accuracy': overall_acc}\n",
    "\n",
    "    # Compute accuracy per category\n",
    "    for category in all_categories:\n",
    "        cat_group = group[group['Change'] == category]\n",
    "        cat_total = len(cat_group)\n",
    "        if cat_total:\n",
    "            correct_cat = (cat_group['Change'] == cat_group['Prediction_Label']).sum()\n",
    "            cat_acc = round((correct_cat / cat_total) * 100, 2)\n",
    "        else:\n",
    "            cat_acc = np.nan\n",
    "        result[f'acc_{category}'] = cat_acc\n",
    "\n",
    "    return pd.Series(result)\n",
    "\n",
    "# Apply the accuracy function per Census Block Group\n",
    "accuracy_by_id = df.groupby('ID').apply(compute_accuracy).reset_index()\n",
    "\n",
    "# Load the shapefile\n",
    "gdf = gpd.read_file(shp_file)\n",
    "\n",
    "# Ensure GEOID is string for merging\n",
    "gdf['GEOID'] = gdf['GEOID'].astype(str)\n",
    "\n",
    "# Merge shapefile with accuracy data\n",
    "merged_gdf = gdf.merge(accuracy_by_id, how='left', left_on='GEOID', right_on='ID')\n",
    "\n",
    "# Identify accuracy columns (those starting with 'acc_' or 'overall_accuracy')\n",
    "accuracy_cols = [col for col in merged_gdf.columns if col.startswith('acc_') or col == 'overall_accuracy']\n",
    "print(accuracy_cols)\n",
    "# Replace NaN with -9999 in only those columns\n",
    "merged_gdf[accuracy_cols] = merged_gdf[accuracy_cols].fillna(-9999)\n",
    "\n",
    "# Export the merged shapefile.\n",
    "merged_gdf.to_file(output_shp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
